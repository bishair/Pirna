{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN99Xy5qAp3VtmqQsp0RH69",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bishair/Pirna/blob/main/G10-AddedDates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eKz4YKIm6D7F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from math import sqrt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_file = files.upload()"
      ],
      "metadata": {
        "id": "A_behW_96QZz",
        "outputId": "ac2ba399-2e01-4cf9-d7a2-460a81fe4cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0188c5b-dbf1-4cf6-9727-84cc03c82602\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0188c5b-dbf1-4cf6-9727-84cc03c82602\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving riverL.xlsx to riverL (2).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the groundwater level data\n",
        "gw_data = pd.read_excel('groundwater.xlsx')\n",
        "gw_data.dropna(inplace=True)\n",
        "gw_data['Date'] = pd.to_datetime(gw_data['Date'], format='%d/%m/%Y %H:%M')\n",
        "print(gw_data)\n",
        "\n",
        "# Read the river water level data\n",
        "river_data = pd.read_excel('riverL.xlsx')\n",
        "river_data['Date'] = pd.to_datetime(river_data['Date'], format='%d/%m/%Y %H:%M')\n",
        "\n",
        "# Merge the two datasets on the 'Date' column\n",
        "merged_data = pd.merge_asof(gw_data.sort_values('Date'), river_data.sort_values('Date'), on='Date', direction='nearest')\n",
        "\n",
        "# Set 'Date' as the index\n",
        "merged_data.set_index('Date', inplace=True)\n",
        "\n",
        "resampled_data = merged_data.resample('H').ffill()\n",
        "resampled_data = resampled_data[1:]\n",
        "print(resampled_data)\n",
        "\n",
        "'''\n",
        "has_nan = resampled_data.isna().any().any()\n",
        "print(has_nan)\n",
        "total_nan_count = resampled_data.isna().sum().sum()\n",
        "print(total_nan_count)\n",
        "nan_per_column = resampled_data.isna().any()\n",
        "print(nan_per_column)\n",
        "nan_count_per_column = resampled_data.isna().sum()\n",
        "print(nan_count_per_column)'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "ipz0Z0UZ8FVn",
        "outputId": "ad1b30bf-64eb-4d84-a448-2da328190260"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Date      G10\n",
            "0     2015-01-30 12:18:00  110.722\n",
            "1     2015-01-30 13:18:00  110.720\n",
            "2     2015-01-30 14:18:00  110.718\n",
            "3     2015-01-30 15:18:00  110.715\n",
            "4     2015-01-30 16:18:00  110.714\n",
            "...                   ...      ...\n",
            "17533 2017-01-30 10:19:00  109.456\n",
            "17534 2017-01-30 11:19:00  109.455\n",
            "17535 2017-01-30 12:19:00  109.456\n",
            "17536 2017-01-30 13:19:00  109.457\n",
            "17537 2017-01-30 14:19:00  109.459\n",
            "\n",
            "[17329 rows x 2 columns]\n",
            "                         G10  River\n",
            "Date                               \n",
            "2015-01-30 13:00:00  110.722  261.0\n",
            "2015-01-30 14:00:00  110.720  260.0\n",
            "2015-01-30 15:00:00  110.718  260.0\n",
            "2015-01-30 16:00:00  110.715  260.0\n",
            "2015-01-30 17:00:00  110.714  260.0\n",
            "...                      ...    ...\n",
            "2017-01-30 10:00:00  109.457  135.0\n",
            "2017-01-30 11:00:00  109.456  136.0\n",
            "2017-01-30 12:00:00  109.455  138.0\n",
            "2017-01-30 13:00:00  109.456  141.0\n",
            "2017-01-30 14:00:00  109.457  144.0\n",
            "\n",
            "[17546 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhas_nan = resampled_data.isna().any().any()\\nprint(has_nan)\\ntotal_nan_count = resampled_data.isna().sum().sum()\\nprint(total_nan_count)\\nnan_per_column = resampled_data.isna().any()\\nprint(nan_per_column)\\nnan_count_per_column = resampled_data.isna().sum()\\nprint(nan_count_per_column)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_steps = 24\n",
        "\n",
        "# Assume merged_data is a DataFrame with 'Date' as index\n",
        "merged_data_copy = merged_data.copy()\n",
        "merged_data_copy.reset_index(inplace=True)\n",
        "dates = merged_data_copy['Date']\n",
        "\n",
        "# Split the merged data (70% training, 30% testing)\n",
        "train_size = int(len(merged_data) * 0.7)\n",
        "merged_data_train = merged_data[:train_size]\n",
        "merged_data_test = merged_data[train_size:]\n",
        "\n",
        "# Split dates corresponding to the data split\n",
        "dates_train = dates[:train_size]\n",
        "dates_test = dates[train_size:]\n",
        "\n",
        "# Apply MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_scaled = scaler.fit_transform(merged_data_train)\n",
        "test_scaled = scaler.transform(merged_data_test)\n",
        "\n",
        "# Save the scaler for future use\n",
        "joblib.dump(scaler, 'scaler.gz')\n",
        "\n",
        "def create_sequences_with_dates(data, dates, n_steps):\n",
        "    \"\"\"\n",
        "    Create sequences along with corresponding dates.\n",
        "    \"\"\"\n",
        "    X, y, dates_seq = [], [], []\n",
        "    for i in range(n_steps, len(data)):\n",
        "        X.append(data[i-n_steps:i, :])\n",
        "        y.append(data[i, 0])\n",
        "        # Capture the full range of dates for each sequence\n",
        "        dates_seq.append(dates.iloc[i - n_steps + 1 : i + 1])\n",
        "    return np.array(X), np.array(y), np.array(dates_seq)\n",
        "\n",
        "# Create sequences for training and testing sets\n",
        "X_train, y_train, dates_train_seq = create_sequences_with_dates(train_scaled, dates_train, n_steps)\n",
        "X_test, y_test, dates_test_seq = create_sequences_with_dates(test_scaled, dates_test, n_steps)\n",
        "\n",
        "# Print shapes of X_train, y_train, X_test, y_test for verification\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "print(dates_test_seq)"
      ],
      "metadata": {
        "id": "Gohy8wy52sCU",
        "outputId": "a85f8980-615c-4241-df36-93f102cf246b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (12106, 24, 2)\n",
            "y_train shape: (12106,)\n",
            "X_test shape: (5175, 24, 2)\n",
            "y_test shape: (5175,)\n",
            "[['2016-06-19T16:13:00.000000000' '2016-06-19T17:13:00.000000000'\n",
            "  '2016-06-19T18:13:00.000000000' ... '2016-06-20T13:13:00.000000000'\n",
            "  '2016-06-20T14:13:00.000000000' '2016-06-20T15:13:00.000000000']\n",
            " ['2016-06-19T17:13:00.000000000' '2016-06-19T18:13:00.000000000'\n",
            "  '2016-06-19T19:13:00.000000000' ... '2016-06-20T14:13:00.000000000'\n",
            "  '2016-06-20T15:13:00.000000000' '2016-06-20T16:13:00.000000000']\n",
            " ['2016-06-19T18:13:00.000000000' '2016-06-19T19:13:00.000000000'\n",
            "  '2016-06-19T20:13:00.000000000' ... '2016-06-20T15:13:00.000000000'\n",
            "  '2016-06-20T16:13:00.000000000' '2016-06-20T17:13:00.000000000']\n",
            " ...\n",
            " ['2017-01-29T13:19:00.000000000' '2017-01-29T14:19:00.000000000'\n",
            "  '2017-01-29T15:19:00.000000000' ... '2017-01-30T10:19:00.000000000'\n",
            "  '2017-01-30T11:19:00.000000000' '2017-01-30T12:19:00.000000000']\n",
            " ['2017-01-29T14:19:00.000000000' '2017-01-29T15:19:00.000000000'\n",
            "  '2017-01-29T16:19:00.000000000' ... '2017-01-30T11:19:00.000000000'\n",
            "  '2017-01-30T12:19:00.000000000' '2017-01-30T13:19:00.000000000']\n",
            " ['2017-01-29T15:19:00.000000000' '2017-01-29T16:19:00.000000000'\n",
            "  '2017-01-29T17:19:00.000000000' ... '2017-01-30T12:19:00.000000000'\n",
            "  '2017-01-30T13:19:00.000000000' '2017-01-30T14:19:00.000000000']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train, X_train.shape)"
      ],
      "metadata": {
        "id": "80cC_yFQB9kt",
        "outputId": "4765450d-52a4-4f53-ccc4-97041a2e1354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.8510427  0.66666667]\n",
            "  [0.85004965 0.66287879]\n",
            "  [0.8490566  0.66287879]\n",
            "  ...\n",
            "  [0.83366435 0.65909091]\n",
            "  [0.8326713  0.65909091]\n",
            "  [0.83118173 0.66287879]]\n",
            "\n",
            " [[0.85004965 0.66287879]\n",
            "  [0.8490566  0.66287879]\n",
            "  [0.84756703 0.66287879]\n",
            "  ...\n",
            "  [0.8326713  0.65909091]\n",
            "  [0.83118173 0.66287879]\n",
            "  [0.83118173 0.66666667]]\n",
            "\n",
            " [[0.8490566  0.66287879]\n",
            "  [0.84756703 0.66287879]\n",
            "  [0.84707051 0.66287879]\n",
            "  ...\n",
            "  [0.83118173 0.66287879]\n",
            "  [0.83118173 0.66666667]\n",
            "  [0.82969215 0.67045455]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.32820258 0.36363636]\n",
            "  [0.3306852  0.35984848]\n",
            "  [0.3346574  0.35984848]\n",
            "  ...\n",
            "  [0.36494538 0.36363636]\n",
            "  [0.36693148 0.35984848]\n",
            "  [0.36842105 0.35984848]]\n",
            "\n",
            " [[0.3306852  0.35984848]\n",
            "  [0.3346574  0.35984848]\n",
            "  [0.3366435  0.35606061]\n",
            "  ...\n",
            "  [0.36693148 0.35984848]\n",
            "  [0.36842105 0.35984848]\n",
            "  [0.36891758 0.35606061]]\n",
            "\n",
            " [[0.3346574  0.35984848]\n",
            "  [0.3366435  0.35606061]\n",
            "  [0.33912612 0.35227273]\n",
            "  ...\n",
            "  [0.36842105 0.35984848]\n",
            "  [0.36891758 0.35606061]\n",
            "  [0.36991063 0.35606061]]] (12106, 24, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test, X_test.shape)"
      ],
      "metadata": {
        "id": "Cdes7NnzCBEy",
        "outputId": "ed54ad9a-4ae0-460c-faa2-e65dbb4d40ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.37239325 0.35227273]\n",
            "  [0.37288977 0.35227273]\n",
            "  [0.3733863  0.35227273]\n",
            "  ...\n",
            "  [0.38331678 0.34848485]\n",
            "  [0.38381331 0.34848485]\n",
            "  [0.38430983 0.34469697]]\n",
            "\n",
            " [[0.37288977 0.35227273]\n",
            "  [0.3733863  0.35227273]\n",
            "  [0.37487587 0.35227273]\n",
            "  ...\n",
            "  [0.38381331 0.34848485]\n",
            "  [0.38430983 0.34469697]\n",
            "  [0.38480636 0.34469697]]\n",
            "\n",
            " [[0.3733863  0.35227273]\n",
            "  [0.37487587 0.35227273]\n",
            "  [0.37586892 0.35227273]\n",
            "  ...\n",
            "  [0.38430983 0.34469697]\n",
            "  [0.38480636 0.34469697]\n",
            "  [0.38480636 0.34090909]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.2428004  0.21212121]\n",
            "  [0.2428004  0.20833333]\n",
            "  [0.24230387 0.20454545]\n",
            "  ...\n",
            "  [0.22293942 0.18939394]\n",
            "  [0.2224429  0.19318182]\n",
            "  [0.22194638 0.20075758]]\n",
            "\n",
            " [[0.2428004  0.20833333]\n",
            "  [0.24230387 0.20454545]\n",
            "  [0.24180735 0.1969697 ]\n",
            "  ...\n",
            "  [0.2224429  0.19318182]\n",
            "  [0.22194638 0.20075758]\n",
            "  [0.2224429  0.21212121]]\n",
            "\n",
            " [[0.24230387 0.20454545]\n",
            "  [0.24180735 0.1969697 ]\n",
            "  [0.2408143  0.19318182]\n",
            "  ...\n",
            "  [0.22194638 0.20075758]\n",
            "  [0.2224429  0.21212121]\n",
            "  [0.22293942 0.22348485]]] (5175, 24, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train, y_train.shape)"
      ],
      "metadata": {
        "id": "U_p3UDnRDkO-",
        "outputId": "cec39dba-37c9-4ec7-a7f4-edc9830843b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.83118173 0.82969215 0.82969215 ... 0.36891758 0.36991063 0.3714002 ] (12106,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test, y_test.shape)"
      ],
      "metadata": {
        "id": "uCqVjDG-Dom2",
        "outputId": "f32b76f1-7813-4cbb-ce33-bda03c830957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.38480636 0.38480636 0.38629593 ... 0.2224429  0.22293942 0.22393247] (5175,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.regularizers import l1_l2\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(units=50, return_sequences=True, input_shape=input_shape,   #input shape => (timesteps, features).  X => (samples, timesteps, features)\n",
        "         dropout=0.2, recurrent_dropout=0.2,\n",
        "         kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=64)\n"
      ],
      "metadata": {
        "id": "5ClHv6jDDro3",
        "outputId": "2522f7ee-8dcf-46ae-9d30-167cd0b5fa85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/190 [==============================] - 21s 79ms/step - loss: 0.1567\n",
            "Epoch 2/50\n",
            "190/190 [==============================] - 16s 82ms/step - loss: 0.0104\n",
            "Epoch 3/50\n",
            "190/190 [==============================] - 15s 78ms/step - loss: 0.0065\n",
            "Epoch 4/50\n",
            "190/190 [==============================] - 15s 80ms/step - loss: 0.0058\n",
            "Epoch 5/50\n",
            "190/190 [==============================] - 15s 77ms/step - loss: 0.0049\n",
            "Epoch 6/50\n",
            "190/190 [==============================] - 15s 79ms/step - loss: 0.0046\n",
            "Epoch 7/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0046\n",
            "Epoch 8/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0045\n",
            "Epoch 9/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0041\n",
            "Epoch 10/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0041\n",
            "Epoch 11/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0038\n",
            "Epoch 12/50\n",
            "190/190 [==============================] - 16s 87ms/step - loss: 0.0038\n",
            "Epoch 13/50\n",
            "190/190 [==============================] - 15s 79ms/step - loss: 0.0037\n",
            "Epoch 14/50\n",
            "190/190 [==============================] - 15s 79ms/step - loss: 0.0036\n",
            "Epoch 15/50\n",
            "190/190 [==============================] - 15s 78ms/step - loss: 0.0037\n",
            "Epoch 16/50\n",
            "190/190 [==============================] - 15s 77ms/step - loss: 0.0034\n",
            "Epoch 17/50\n",
            "190/190 [==============================] - 15s 79ms/step - loss: 0.0032\n",
            "Epoch 18/50\n",
            "190/190 [==============================] - 15s 77ms/step - loss: 0.0033\n",
            "Epoch 19/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0033\n",
            "Epoch 20/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0032\n",
            "Epoch 21/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0032\n",
            "Epoch 22/50\n",
            "190/190 [==============================] - 15s 81ms/step - loss: 0.0030\n",
            "Epoch 23/50\n",
            "190/190 [==============================] - 14s 76ms/step - loss: 0.0029\n",
            "Epoch 24/50\n",
            "190/190 [==============================] - 15s 80ms/step - loss: 0.0030\n",
            "Epoch 25/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0031\n",
            "Epoch 26/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0031\n",
            "Epoch 27/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0030\n",
            "Epoch 28/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0031\n",
            "Epoch 29/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0029\n",
            "Epoch 30/50\n",
            "190/190 [==============================] - 14s 76ms/step - loss: 0.0029\n",
            "Epoch 31/50\n",
            "190/190 [==============================] - 15s 79ms/step - loss: 0.0029\n",
            "Epoch 32/50\n",
            "190/190 [==============================] - 15s 80ms/step - loss: 0.0028\n",
            "Epoch 33/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0030\n",
            "Epoch 34/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0028\n",
            "Epoch 35/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0028\n",
            "Epoch 36/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0028\n",
            "Epoch 37/50\n",
            "190/190 [==============================] - 15s 80ms/step - loss: 0.0029\n",
            "Epoch 38/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0028\n",
            "Epoch 39/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0027\n",
            "Epoch 40/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0027\n",
            "Epoch 41/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0029\n",
            "Epoch 42/50\n",
            "190/190 [==============================] - 15s 81ms/step - loss: 0.0029\n",
            "Epoch 43/50\n",
            "190/190 [==============================] - 15s 80ms/step - loss: 0.0027\n",
            "Epoch 44/50\n",
            "190/190 [==============================] - 14s 76ms/step - loss: 0.0027\n",
            "Epoch 45/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0027\n",
            "Epoch 46/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0027\n",
            "Epoch 47/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0027\n",
            "Epoch 48/50\n",
            "190/190 [==============================] - 14s 74ms/step - loss: 0.0027\n",
            "Epoch 49/50\n",
            "190/190 [==============================] - 14s 75ms/step - loss: 0.0027\n",
            "Epoch 50/50\n",
            "190/190 [==============================] - 15s 81ms/step - loss: 0.0026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c632ae07610>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('lstmmodel.h5')\n",
        "model = load_model('lstmmodel.h5')\n",
        "scaler = joblib.load('scaler.gz')"
      ],
      "metadata": {
        "id": "NeRx0Clm6wkU",
        "outputId": "c37c9cb8-86c0-40ba-8bf3-c54037298174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrain the model with new data\n",
        "def retrain_model(model, X_new, y_new, epochs=5, batch_size=32):\n",
        "    # Partial retraining of the model with new data\n",
        "    model.fit(X_new, y_new, epochs=epochs, batch_size=batch_size, shuffle=True)\n",
        "    return model\n",
        "\n",
        "'''# Function to update y_train and recalculate statistics\n",
        "def update_training_data(new_data, y_train, max_length=10000):\n",
        "    updated_y_train = np.append(y_train, new_data)\n",
        "    if len(updated_y_train) > max_length:\n",
        "        updated_y_train = updated_y_train[-max_length:]\n",
        "    mean_y_train = np.mean(updated_y_train)\n",
        "    std_y_train = np.std(updated_y_train)\n",
        "    return updated_y_train, mean_y_train, std_y_train '''"
      ],
      "metadata": {
        "id": "SvQCwgRqrEYq",
        "outputId": "114ad70e-30c4-4e38-db70-b48ab5728bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Function to update y_train and recalculate statistics\\ndef update_training_data(new_data, y_train, max_length=10000):\\n    updated_y_train = np.append(y_train, new_data)\\n    if len(updated_y_train) > max_length:\\n        updated_y_train = updated_y_train[-max_length:]\\n    mean_y_train = np.mean(updated_y_train)\\n    std_y_train = np.std(updated_y_train)\\n    return updated_y_train, mean_y_train, std_y_train '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "window_size = 24\n",
        "\n",
        "actual_values = []\n",
        "predicted_values = []\n",
        "errors = []\n",
        "dates_for_plotting = []  # Store dates for plotting\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    X_input = X_test[i, :, :]\n",
        "    X_input = np.reshape(X_input, (1, X_input.shape[0], X_input.shape[1]))\n",
        "\n",
        "    # Make a prediction\n",
        "    forecast = model.predict(X_input)\n",
        "    dummy = np.zeros((1, 2))\n",
        "    dummy[:, 0] = forecast[:, 0]\n",
        "    forecasted_value = scaler.inverse_transform(dummy)[0, 0]\n",
        "    predicted_values.append(forecasted_value)\n",
        "\n",
        "    actual = y_test[i] if i < len(y_test) else None\n",
        "    if actual is not None:\n",
        "        actual_transformed = scaler.inverse_transform([[actual, 0]])[0, 0]\n",
        "        actual_values.append(actual_transformed)\n",
        "\n",
        "    error = abs(forecasted_value - actual_transformed)\n",
        "    errors.append(error)\n",
        "\n",
        "    # Convert the last date of each sequence to datetime for plotting\n",
        "    last_date = pd.to_datetime(dates_test_seq[i][-1])\n",
        "    dates_for_plotting.append(last_date)\n",
        "\n",
        "    ax.clear()\n",
        "    ax.plot(dates_for_plotting, actual_values, label='Observed', color='blue')\n",
        "    ax.plot(dates_for_plotting, predicted_values, label='Predicted', color='red')\n",
        "    ax.set_title('G10')\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel('Water Level')\n",
        "    ax.legend()\n",
        "\n",
        "    if len(errors) >= window_size:\n",
        "        windowed_errors = errors[-window_size:]\n",
        "        mean_error = np.mean(windowed_errors)\n",
        "        std_error = np.std(windowed_errors)\n",
        "        threshold = mean_error + 3 * std_error\n",
        "\n",
        "        windowed_anomalies = [j for j, e in enumerate(windowed_errors) if e > threshold]\n",
        "        # Anomaly detection and model retraining code...\n",
        "\n",
        "    display(fig)\n",
        "    plt.pause(0.5)\n",
        "    clear_output(wait=True)\n",
        "\n",
        "plt.close(fig)\n"
      ],
      "metadata": {
        "id": "mxNHComhzxXL",
        "outputId": "834ccc8d-57af-4853-a315-cc203d0ffefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fc15825f11d0>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdummy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4vkKqJTPOZCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}